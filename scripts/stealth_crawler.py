#!/usr/bin/env python3
"""
ğŸ•·ï¸ Playwright ìŠ¤í…”ìŠ¤ í¬ë¡¤ëŸ¬
0.3ì´ˆ ê°„ê²©ìœ¼ë¡œ ì—¬ëŸ¬ ë²ˆ í´ë¦­í•˜ëŠ” ê³ ê¸‰ í¬ë¡¤ëŸ¬
"""

import asyncio
import random
from playwright.async_api import async_playwright
from typing import List, Dict, Any
import json
import time

class StealthCrawler:
    def __init__(self):
        self.stealth_options = {
            'user_agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'viewport': {'width': 1920, 'height': 1080},
            'locale': 'en-US',
            'timezone_id': 'America/New_York'
        }
    
    async def create_stealth_browser(self, playwright):
        """ìŠ¤í…”ìŠ¤ ë¸Œë¼ìš°ì € ìƒì„±"""
        browser = await playwright.chromium.launch(
            headless=True,  # Falseë¡œ í•˜ë©´ ë¸Œë¼ìš°ì € ì°½ì´ ë³´ì„
            args=[
                '--disable-blink-features=AutomationControlled',
                '--no-sandbox',
                '--disable-setuid-sandbox',
                '--disable-dev-shm-usage',
                '--disable-accelerated-2d-canvas',
                '--no-first-run',
                '--disable-background-networking',
                '--disable-default-apps',
                '--disable-extensions',
                '--disable-sync',
                '--disable-translate',
                '--hide-scrollbars',
                '--metrics-recording-only',
                '--mute-audio',
                '--no-default-browser-check',
                '--safebrowsing-disable-auto-update',
                '--disable-web-security',
                '--disable-features=VizDisplayCompositor'
            ]
        )
        
        context = await browser.new_context(
            user_agent=self.stealth_options['user_agent'],
            viewport=self.stealth_options['viewport'],
            locale=self.stealth_options['locale'],
            timezone_id=self.stealth_options['timezone_id']
        )
        
        # ìë°”ìŠ¤í¬ë¦½íŠ¸ë¡œ webdriver ê°ì§€ ë°©ì§€
        await context.add_init_script("""
            Object.defineProperty(navigator, 'webdriver', {
                get: () => undefined,
            });
            
            window.chrome = {
                runtime: {},
            };
            
            Object.defineProperty(navigator, 'plugins', {
                get: () => [1, 2, 3, 4, 5],
            });
            
            Object.defineProperty(navigator, 'languages', {
                get: () => ['en-US', 'en'],
            });
        """)
        
        return browser, context
    
    async def smart_click_sequence(self, page, selectors: List[str], interval: float = 0.3):
        """ìŠ¤ë§ˆíŠ¸ í´ë¦­ ì‹œí€€ìŠ¤ (0.3ì´ˆ ê°„ê²©)"""
        results = []
        
        for selector in selectors:
            try:
                # ìš”ì†Œê°€ ë¡œë“œë  ë•Œê¹Œì§€ ëŒ€ê¸°
                await page.wait_for_selector(selector, timeout=5000)
                
                # ì¸ê°„ê°™ì€ ë§ˆìš°ìŠ¤ ì›€ì§ì„ ì‹œë®¬ë ˆì´ì…˜
                element = await page.query_selector(selector)
                if element:
                    # ìš”ì†Œì˜ ì¤‘ì‹¬ì  ê³„ì‚°
                    box = await element.bounding_box()
                    if box:
                        # ì•½ê°„ì˜ ëœë¤ ì˜¤í”„ì…‹ ì¶”ê°€ (ì¸ê°„ì²˜ëŸ¼)
                        x = box['x'] + box['width'] / 2 + random.uniform(-5, 5)
                        y = box['y'] + box['height'] / 2 + random.uniform(-5, 5)
                        
                        # ë§ˆìš°ìŠ¤ ì´ë™ í›„ í´ë¦­
                        await page.mouse.move(x, y)
                        await asyncio.sleep(random.uniform(0.1, 0.2))
                        await page.mouse.click(x, y)
                        
                        results.append({
                            'selector': selector,
                            'clicked': True,
                            'timestamp': time.time()
                        })
                        
                        print(f"âœ… í´ë¦­ ì„±ê³µ: {selector}")
                    else:
                        print(f"âŒ ìš”ì†Œ ë°•ìŠ¤ ì—†ìŒ: {selector}")
                else:
                    print(f"âŒ ìš”ì†Œ ì—†ìŒ: {selector}")
                
                # ê°„ê²© ëŒ€ê¸° (0.3ì´ˆ + ëœë¤)
                await asyncio.sleep(interval + random.uniform(0.05, 0.15))
                
            except Exception as e:
                print(f"âŒ í´ë¦­ ì‹¤íŒ¨ {selector}: {e}")
                results.append({
                    'selector': selector,
                    'clicked': False,
                    'error': str(e),
                    'timestamp': time.time()
                })
        
        return results
    
    async def extract_content(self, page, content_selectors: Dict[str, str]) -> Dict[str, Any]:
        """ì½˜í…ì¸  ì¶”ì¶œ"""
        content = {}
        
        for key, selector in content_selectors.items():
            try:
                elements = await page.query_selector_all(selector)
                if elements:
                    texts = []
                    for element in elements:
                        text = await element.inner_text()
                        if text.strip():
                            texts.append(text.strip())
                    content[key] = texts
                else:
                    content[key] = []
            except Exception as e:
                print(f"âŒ ì½˜í…ì¸  ì¶”ì¶œ ì‹¤íŒ¨ {key}: {e}")
                content[key] = []
        
        return content
    
    async def crawl_with_multiple_clicks(self, url: str, click_selectors: List[str], content_selectors: Dict[str, str], max_clicks: int = 10) -> Dict[str, Any]:
        """ë©€í‹° í´ë¦­ í¬ë¡¤ë§"""
        print(f"ğŸš€ ìŠ¤í…”ìŠ¤ í¬ë¡¤ë§ ì‹œì‘: {url}")
        
        async with async_playwright() as playwright:
            browser, context = await self.create_stealth_browser(playwright)
            page = await context.new_page()
            
            try:
                # í˜ì´ì§€ ë¡œë“œ
                await page.goto(url, wait_until='networkidle')
                await asyncio.sleep(2)  # ì´ˆê¸° ë¡œë”© ëŒ€ê¸°
                
                # ìŠ¤í¬ë¡¤ ë‹¤ìš´ (ì½˜í…ì¸  ë¡œë“œ)
                await page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
                await asyncio.sleep(1)
                
                # ë‹¤ì¤‘ í´ë¦­ ì‹¤í–‰
                click_results = await self.smart_click_sequence(
                    page, 
                    click_selectors[:max_clicks], 
                    interval=0.3
                )
                
                # ì½˜í…ì¸  ì¶”ì¶œ
                content = await self.extract_content(page, content_selectors)
                
                # í˜ì´ì§€ ì •ë³´ ìˆ˜ì§‘
                title = await page.title()
                current_url = page.url
                
                return {
                    'url': current_url,
                    'original_url': url,
                    'title': title,
                    'content': content,
                    'click_results': click_results,
                    'success': True,
                    'timestamp': time.time()
                }
                
            except Exception as e:
                print(f"âŒ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
                return {
                    'url': url,
                    'title': '',
                    'content': {},
                    'click_results': [],
                    'success': False,
                    'error': str(e),
                    'timestamp': time.time()
                }
            
            finally:
                await browser.close()

# ì‹¤ì œ í¬ë¡¤ë§ ì‹¤í–‰ í•¨ìˆ˜ë“¤
async def crawl_tech_news():
    """í…Œí¬ ë‰´ìŠ¤ í¬ë¡¤ë§"""
    crawler = StealthCrawler()
    
    # í¬ë¡¤ë§í•  ì‚¬ì´íŠ¸ë“¤
    sites = [
        {
            'url': 'https://techcrunch.com/category/artificial-intelligence/',
            'click_selectors': [
                'a[href*="artificial-intelligence"]',
                'button[aria-label="Load more"]',
                '.load-more',
                '.show-more-button'
            ],
            'content_selectors': {
                'headlines': 'h2 a, h3 a, .post-title a',
                'summaries': '.excerpt, .summary, p:first-of-type',
                'dates': '.post-date, time, .published-date'
            }
        }
    ]
    
    results = []
    for site in sites:
        result = await crawler.crawl_with_multiple_clicks(
            site['url'],
            site['click_selectors'],
            site['content_selectors'],
            max_clicks=8
        )
        results.append(result)
        
        # ì‚¬ì´íŠ¸ ê°„ ëŒ€ê¸°
        await asyncio.sleep(2)
    
    return results

async def crawl_youtube_trending():
    """YouTube íŠ¸ë Œë”© í˜ì´ì§€ í¬ë¡¤ë§"""
    crawler = StealthCrawler()
    
    result = await crawler.crawl_with_multiple_clicks(
        'https://www.youtube.com/feed/trending',
        [
            'a#video-title',
            'button[aria-label="Show more"]',
            '.ytd-video-renderer a',
            '.compact-media-item a'
        ],
        {
            'video_titles': '#video-title',
            'channel_names': '.ytd-channel-name a',
            'view_counts': '.ytd-video-meta-block span:contains("views")',
            'upload_dates': '.ytd-video-meta-block span:contains("ago")'
        },
        max_clicks=12
    )
    
    return result

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
async def test_stealth_crawler():
    print("ğŸ§ª ìŠ¤í…”ìŠ¤ í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    # í…Œí¬ ë‰´ìŠ¤ í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸
    news_results = await crawl_tech_news()
    print(f"ğŸ“° ë‰´ìŠ¤ í¬ë¡¤ë§ ê²°ê³¼: {len(news_results)}ê°œ ì‚¬ì´íŠ¸")
    
    # YouTube íŠ¸ë Œë”© í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸  
    youtube_result = await crawl_youtube_trending()
    print(f"ğŸ¬ YouTube í¬ë¡¤ë§ ê²°ê³¼: {youtube_result['success']}")
    
    return {
        'news_results': news_results,
        'youtube_result': youtube_result
    }

if __name__ == "__main__":
    asyncio.run(test_stealth_crawler())
